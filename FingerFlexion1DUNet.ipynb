{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX1Wdj10hikt"
      },
      "source": [
        "# Final Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkLBVy2Jhikv"
      },
      "source": [
        "Daryl Hurwitz, Joseph Dong, Jiaru"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU4RALi9hikv"
      },
      "source": [
        "Installing all the libraries needed for Colab and have GPU enabled as Hardware accelerator.  The output for the hidden test will be the `prediction.mat` once all the cells are ran. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jvMYnENhikv",
        "outputId": "bb58d2fb-748d-4c3b-8d5b-213145686998"
      },
      "outputs": [],
      "source": [
        "!pip install -U mne # THE MOST RECENT **STABLE** VERSION: 0.20.7\n",
        "!pip install pytorch-lightning\n",
        "!pip install torchtext\n",
        "!pip install pytorch_model_summary\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GwQ2Pt5hikw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy  import io, interpolate, ndimage, stats\n",
        "from scipy.fftpack import fft, fftfreq\n",
        "from scipy.signal import hamming, cwt, firwin, filtfilt, freqz, decimate, resample\n",
        "from scipy.interpolate import interp1d\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
        "import torch.nn.functional as F\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.accelerators import find_usable_cuda_devices\n",
        "from pytorch_lightning.callbacks import Callback, ModelCheckpoint\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from pytorch_model_summary import summary\n",
        "import wandb\n",
        "import shutil\n",
        "import mne"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5KkmAfzhikw"
      },
      "source": [
        "## 0. Load in files\n",
        "\n",
        "Upload `model1.ckpt`, `model2.ckpt`, `model3.ckpt`, and `truetest_data.mat` to colab.  Followed by running everything in the colab.  Ensure you're using GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zvqyf69a-tRX"
      },
      "outputs": [],
      "source": [
        "# Pickle would not work....\n",
        "Path(f\"{Path().resolve()}/checkpoints\").mkdir( exist_ok=True)\n",
        "src1 = \"/content/model1.ckpt\"\n",
        "src2 = \"/content/model2.ckpt\"\n",
        "src3 = \"/content/model3.ckpt\"\n",
        "dst = \"/content/checkpoints\"\n",
        "shutil.move(src1, dst)\n",
        "shutil.move(src2, dst)\n",
        "shutil.move(src3, dst)\n",
        "#ecog_data = io.loadmat('leaderboard_data.mat')\n",
        "ecog_data = io.loadmat('truetest_data.mat')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL3MyprPhikx"
      },
      "source": [
        "## 1. Normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5FrfwOJhikx"
      },
      "outputs": [],
      "source": [
        "def normalize(ecogdata):\n",
        "    means = np.mean(ecogdata, axis=1, keepdims=True)\n",
        "    stds = np.std(ecogdata, axis=1, keepdims=True)\n",
        "    normalized_data = (ecogdata - means) / stds\n",
        "    common_average = np.median(normalized_data, axis=0, keepdims=True)\n",
        "    normalized_data = normalized_data - common_average\n",
        "    return normalized_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwcKLCUghikx"
      },
      "source": [
        "## 2. Bandpass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fm8tX3gNhikx"
      },
      "outputs": [],
      "source": [
        "def filtered(ecogdata, low_freq, high_freq, sample_rate):\n",
        "    print(\"Removing Noise...\")\n",
        "    harmonics = np.array([i * 50 for i in range(1, (sample_rate // 2) // 50)])\n",
        "    trans = ecogdata.T\n",
        "    raw_filter = mne.filter.filter_data(trans, sfreq = sample_rate,\n",
        "        l_freq = low_freq, h_freq = high_freq, filter_length='10s', phase = 'zero', \n",
        "        fir_window = 'hann', fir_design = 'firwin')\n",
        "    \n",
        "    print(\"Removing Harmonics...\")\n",
        "    raw_notched = mne.filter.notch_filter(raw_filter, Fs = sample_rate,\n",
        "        freqs=harmonics, method='spectrum_fit', filter_length='10s')\n",
        "\n",
        "    return raw_notched"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUsRQY-ahikx"
      },
      "source": [
        "## 3. Convolution with Morlet wavelet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAbKYfKNhikx"
      },
      "outputs": [],
      "source": [
        "def morlet_conv(ecogs, low_freq, high_freq, sample_rate, n_wavelets, decimate = 1):\n",
        "    data = ecogs\n",
        "    num_channels = data.shape[0]\n",
        "    convolutes =  mne.time_frequency.tfr_array_morlet(data.reshape(1, num_channels, -1), sfreq = sample_rate,\n",
        "                                                        freqs = np.logspace(np.log10(low_freq), np.log10(high_freq), n_wavelets), decim = decimate,\n",
        "                                                        output='power', verbose=10, n_jobs=6)[0]\n",
        "    return convolutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6PngNBrhikx"
      },
      "source": [
        "## 4. Downsample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0weQKc_hikx"
      },
      "outputs": [],
      "source": [
        "### Decimation is already carried out by MNE's wavelet library\n",
        "def downsample_decimate(input, down_factor=10):\n",
        "    \"\"\"DEPRECATED, MNE's wavelet library already decimates\n",
        "    input signal sampled at 1000Hz, output siganl sampled at 100Hz, so the downsampling factor is 10\n",
        "    input shape (#samples, #wavelets, #channels), output shape (1/10 #samples, #wavelets, #channels)\"\"\"\n",
        "\n",
        "    downsample = decimate(input, down_factor, axis=0, ftype='fir') # iir seems numerically unstable\n",
        "    return downsample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3I8sqI_hiky"
      },
      "source": [
        "## 5. RobustScalar\n",
        "\n",
        "> Note: an alternative is to do Log10 on the wavelet spectra, then **do**/do not do scale_robust"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2aE1T9Uhiky"
      },
      "outputs": [],
      "source": [
        "\n",
        "def scalerobust(ecogs_train, ecogs_val):\n",
        "    num_channels = ecogs_train.shape[0]\n",
        "    transformer = RobustScaler(unit_variance=True, quantile_range=(.1, .9))\n",
        "    transformer.fit(ecogs_train.T.reshape(-1,num_wavelet*num_channels))\n",
        "    ecog_data_scaled = transformer.transform(ecogs_train.T.reshape(-1,num_wavelet*num_channels)).reshape(-1,num_wavelet, num_channels).T\n",
        "    ecog_data_val_scaled = transformer.transform(ecogs_val.T.reshape(-1,num_wavelet*num_channels)).reshape(-1,num_wavelet, num_channels).T\n",
        "\n",
        "    return ecog_data_scaled, ecog_data_val_scaled\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QXcge1Ghiky"
      },
      "source": [
        "## 6. Signal Shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gySPGzphiky"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "The lag between the dataglove position measurement recording and the \n",
        "amplifier measurement is 37ms.  The relevant physiological range: 0 âˆ’ 200ms.\n",
        "'''\n",
        "\n",
        "def signal_shift(ecogs, fingers, time : float, fs):\n",
        "    \"\"\"Shifts ecogs and finger signals by some set amount time. Requires fs\"\"\"\n",
        "\n",
        "    n_samp_shift = int(time * fs)\n",
        "    # the first motions do not depend on available data\n",
        "    out_fing = fingers[..., n_samp_shift:] \n",
        "    # The latter spectrograms have no corresponding data\n",
        "    out_ecog = ecogs[..., :ecogs.shape[2]-n_samp_shift]\n",
        "\n",
        "    return out_ecog, out_fing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDbF9oHOhiky"
      },
      "source": [
        "# Glove Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhPiGQFqhiky"
      },
      "source": [
        "## 7. Upsample with Bicubic interpolation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2lbe1m8hiky"
      },
      "outputs": [],
      "source": [
        "def finger_interpolation(dataglove_signal, super_sf, true_sf, desired_sf, interpType):\n",
        "        '''\n",
        "        Cubic interpolation since the data was sampled at 25Hz and then upsampled to 1000Hz\n",
        "        '''\n",
        "        downscale_ratio= super_sf // true_sf\n",
        "        upscaling_ratio = desired_sf // true_sf\n",
        " \n",
        "        dgT = dataglove_signal.T #(5, 300000)\n",
        "        finger_flex_true_fs = dgT[:, ::downscale_ratio] #(super-sampled to 1 kHz) which is why we are down sampling (5, 7500)\n",
        "        finger_flex_true_fs = np.c_[finger_flex_true_fs,finger_flex_true_fs.T[-1]]\n",
        "        \n",
        "        ts = np.asarray(range(finger_flex_true_fs.shape[1])) * upscaling_ratio\n",
        "\n",
        "        interpolated_finger_flex_funcs = [interpolate.interp1d(ts, finger_flex_true_fs_ch, kind=interpType) for\n",
        "                                finger_flex_true_fs_ch in finger_flex_true_fs]\n",
        "\n",
        "        ts_needed_hz = np.asarray(range(finger_flex_true_fs.shape[1] * upscaling_ratio)[:-upscaling_ratio])  # Removing the extra added edge\n",
        "        interpolated_finger_flex = np.array([[interpolated_finger_flex_func(t) for t in ts_needed_hz] for \n",
        "                                                interpolated_finger_flex_func in interpolated_finger_flex_funcs])\n",
        "\n",
        "        return interpolated_finger_flex\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTN1JlGvhiky"
      },
      "source": [
        "## 8. MinMax Scaler \n",
        "\n",
        "> Note: when scaling finger features, I would only do affine scaling operations, since otherwise the finger data becomes distorted and our model has to learn on the distortion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcWE_r4vhiky"
      },
      "outputs": [],
      "source": [
        "def scale_minmax(hands_train, hands_val):\n",
        "\n",
        "    mms = MinMaxScaler().fit(hands_train.T)\n",
        "    train = mms.transform(hands_train.T).T\n",
        "    validate = mms.transform(hands_val.T).T\n",
        "    \n",
        "    return train, validate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pxDv5Mahiky"
      },
      "source": [
        "## 9. Fit Model to ECoGs and Fingers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhhYYNJNhiky"
      },
      "outputs": [],
      "source": [
        "# Hard Parameters\n",
        "f_s_ecog = 1000 # Hz\n",
        "f_s_dg = 25 # Hz\n",
        "supered_f_s = 1000 # Hz\n",
        "freq_low, freq_high = 40, 300 # Lower and upper filtration bounds\n",
        "num_wavelet = 40 # Number of wavelets\n",
        "delay = 0.2 # Time delay\n",
        "downsampling_f_s = 100 # Hz\n",
        "upsampling_f_s = downsampling_f_s # Hz\n",
        "shift_time = 0.2 # s. Tunable parameter\n",
        "split_train = 0.7 # proportion\n",
        "subject_num = 1\n",
        "Path(f\"{Path().resolve()}/data\").mkdir(parents=True, exist_ok=True)\n",
        "PATH = f\"{Path().resolve()}/data\"\n",
        "fs_ml = upsampling_f_s\n",
        "n_window = round(0.2 * fs_ml)\n",
        "n_stride = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLpAQad_hiky"
      },
      "source": [
        "### Run Preprocessing Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZmbLH-8hikz"
      },
      "outputs": [],
      "source": [
        "def testpreprocess(ecogdata):\n",
        "    \n",
        "    # Preprocess ECoGs\n",
        "    e = normalize(ecogdata)\n",
        "    e = filtered(e, freq_low, freq_high, f_s_ecog)\n",
        "    e = morlet_conv(e, freq_low, freq_high, f_s_ecog, num_wavelet, 10)\n",
        "    \n",
        "    # Robust scalar\n",
        "    num_channels = e.shape[0]\n",
        "    transformer = RobustScaler(unit_variance=True, quantile_range=(.1, .9))\n",
        "    transformer.fit(e.T.reshape(-1,num_wavelet*num_channels))\n",
        "    e_scaled = transformer.transform(e.T.reshape(-1,num_wavelet*num_channels)).reshape(-1, num_wavelet, num_channels).T\n",
        "\n",
        "    \n",
        "    # Time shift\n",
        "    n_samp_shift = int(shift_time * upsampling_f_s)\n",
        "    e_test = e_scaled[..., :e_scaled.shape[2]-n_samp_shift]\n",
        "    print(e_test.shape)\n",
        "    return e_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my6Dn6c6hikz"
      },
      "source": [
        "### Save preprocessing output, Clear workspace, Reload preprocessing output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyidaAF6hikz"
      },
      "outputs": [],
      "source": [
        "def save_preprocessing(patient : int, ecogdata, dgdata = None,  path = PATH, val=None, reshape=False):\n",
        "\n",
        "    \"\"\"Saves the output of preprocess() into .npy arrays, to free up RAM\n",
        "    \n",
        "    Doesn't actually do the freeing up RAM part though\"\"\"\n",
        "    num_channels = ecogdata.shape[2]\n",
        "    Path(f\"{path}/train\").mkdir(parents=True, exist_ok=True)\n",
        "    Path(f\"{path}/val\").mkdir(parents=True, exist_ok=True)\n",
        "    Path(f\"{path}/test\").mkdir(parents=True, exist_ok=True)\n",
        "    ecog_path = f\"{path}/train/patient{patient}_ecog.npy\" if val is None else f\"{path}/val/patient{patient}_ecog.npy\" if \\\n",
        "        val is True else f\"{path}/test/patient{patient}_ecog.npy\"\n",
        "    dg_path = f\"{path}/train/patient{patient}_hand.npy\" if val is None else f\"{path}/val/patient{patient}_hand.npy\" if \\\n",
        "        val is True else f\"{path}/test/patient{patient}_hand.npy\"\n",
        "    if reshape:\n",
        "        ecog_data = ecogdata.reshape(num_channels*num_wavelet,-1)\n",
        "    if os.path.isfile(ecog_path):\n",
        "        os.remove(ecog_path)\n",
        "    if os.path.isfile(dg_path):\n",
        "        os.remove(dg_path)\n",
        "    np.save(ecog_path, ecogdata)\n",
        "    np.save(dg_path, dgdata)\n",
        "\n",
        "\n",
        "def load_preprocessing(patient : int, path, val = None):\n",
        "    \"\"\"Loads preprocessing data from file. Same output format as preprocess().\"\"\"\n",
        "    ecog_path = f\"{path}/train/patient{patient}_ecog.npy\" if val is None else f\"{path}/val/patient{patient}_ecog.npy\" if \\\n",
        "        val is True else f\"{path}/test/patient{patient}_ecog.npy\"\n",
        "    dg_path = f\"{path}/train/patient{patient}_hand.npy\" if val is None else f\"{path}/val/patient{patient}_hand.npy\" if \\\n",
        "        val is True else f\"{path}/test/patient{patient}_hand.npy\"\n",
        "    ecog_data = np.load(ecog_path)\n",
        "    if val == False:\n",
        "      dg_data = ecog_data\n",
        "    else:\n",
        "      dg_data = np.load(dg_path)\n",
        "    return ecog_data, dg_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSMpwIP8hikz"
      },
      "source": [
        "### Define dataset classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0JZrluwhikz"
      },
      "outputs": [],
      "source": [
        "class Dataset(Dataset):\n",
        "    \"\"\"Includes both an ECoG and its corresponding finger movements\"\"\"\n",
        "    \n",
        "    def __init__(self, ecog : str, dg : str, n_window : float, n_stride : int, train = False ):\n",
        "        \n",
        "        self.ecog = np.load(ecog).astype('float32')\n",
        "        self.dg = np.load(dg).astype('float32')\n",
        "        self.n_window = n_window\n",
        "        self.n_stride = 1\n",
        "        self.n_samples = self.ecog.shape[2]\n",
        "        self.dataset_len = (self.n_samples - self.n_window) // self.n_stride       # Assuming all samples are the same length\n",
        "        \n",
        "        self.train = train # when to train, val, or test\n",
        "\n",
        "    def __len__(self):\n",
        "        \n",
        "        return self.dataset_len\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        startind = self.n_stride * index\n",
        "        stopind = startind + self.n_window\n",
        "\n",
        "        return self.ecog[startind : stopind, ...], self.fing[startind : stopind, ...]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oONhd0Lnhikz"
      },
      "outputs": [],
      "source": [
        "class DataModule(pl.LightningDataModule):\n",
        "    \n",
        "    def __init__(self, patient : int, batch_size : 128, window_n : float,  path=PATH):\n",
        "        \"\"\"For reference, Fingerflex uses batch sizes of 128\"\"\"\n",
        "        self.window_n = window_n\n",
        "        \n",
        "        self.patient = patient\n",
        "        self.batch_size = batch_size\n",
        "        self.path = path\n",
        "    \n",
        "    def setup(self, stage = None):\n",
        "\n",
        "        if stage == \"fit\" or stage is None:\n",
        "            self.ds_train = Dataset(f\"{self.path}/train/patient{self.patient}_ecog.npy\", \n",
        "                                    f\"{self.path}/train/patient{self.patient}_hand.npy\",\n",
        "                                    n_window=self.window_n, Train = True )\n",
        "            self.ds_val = Dataset(f\"{self.path}/val/patient{self.patient}_ecog.npy\", \n",
        "                                    f\"{self.path}/val/patient{self.patient}_hand.npy\",\n",
        "                                    n_window=self.window_n)\n",
        "        if stage == \"test\" or stage is None:\n",
        "            self.ds_test = Dataset(f\"{self.path}/test/patient{self.patient}_ecog.npy\", \n",
        "                                   n_window=self.window_n )\n",
        "        \n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.ds_train, batch_size=self.batch_size, num_workers=3, shuffle=True)\n",
        "    \n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.ds_val, batch_size=self.batch_size)\n",
        "    \n",
        "    def test_dataloader(self): \n",
        "        return DataLoader(self.ds_test, batch_size=self.batch_size)\n",
        "\n",
        "def correlation_metric(x, y):\n",
        "    cos_metric = nn.CosineSimilarity(dim=-1, eps=1e-08)\n",
        "    cos_sim = torch.mean(cos_metric(x, y))\n",
        "    return cos_sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0QrQLnNhikz"
      },
      "outputs": [],
      "source": [
        "class Runner(pl.LightningModule):\n",
        "    \n",
        "    def __init__(self, model, learning_rate = 8.42e-5, decay_rate = 1e-6):\n",
        "        super().__init__()\n",
        "        self.model = model \n",
        "        self.lr = learning_rate\n",
        "        self.decay = decay_rate\n",
        "        \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self.model(x)\n",
        "        loss = F.mse_loss(y_hat, y)\n",
        "        corr = correlation_metric(y_hat, y)\n",
        "        self.log(\"Train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "\n",
        "        self.log(f\"cosine_dst_train\", corr, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return 0.5*loss + 0.5*(1. - corr) \n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self.model(x)\n",
        "        loss = F.mse_loss(y_hat, y)\n",
        "        corr = correlation_metric(y_hat, y)\n",
        "        assert x.shape == y.shape  \n",
        "        correlation = np.corrcoef(y_hat, y)[0, 1]\n",
        "        self.log(\"Validation Loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.log(\"Validation Correlation\", correlation, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.log(\"cosine_dst_val\", corr, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "        \n",
        "        return y_hat \n",
        "    \n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self.model(x)\n",
        "        assert x.shape == y.shape  \n",
        "        correlation = np.corrcoef(y_hat, y)[0, 1]\n",
        "        loss = F.mse_loss(y_hat, y)\n",
        "        self.log(\"Validation Correlation\", correlation, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.log(\"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "        \n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=1e-6) # set optimizer, lr and L2 regularization coeff\n",
        "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=3, verbose=True)  # Add ReduceLROnPlateau scheduler\n",
        "        return {\n",
        "            'optimizer': optimizer,\n",
        "            'lr_scheduler': {\n",
        "                'scheduler': scheduler,\n",
        "                'monitor': 'val_loss'\n",
        "            }\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Uj2duLhikz"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cl0xjE_-hikz"
      },
      "outputs": [],
      "source": [
        "class Conv(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1, prob=0.1):\n",
        "        super(Conv, self).__init__()\n",
        "        \n",
        "        self.conv1d = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, bias=False, padding='same')\n",
        "        self.norm = nn.LayerNorm(out_channels)\n",
        "        self.activation = nn.GELU()  ## maybe swap this out with other activation function\n",
        "        self.drop = nn.Dropout(p=prob)\n",
        "        self.downsample = nn.MaxPool1d(kernel_size=stride, stride=stride)\n",
        "        self.stride = stride\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1d(x)\n",
        "        x = torch.transpose(x, -2, -1) \n",
        "        x = self.norm(x)\n",
        "        x = torch.transpose(x, -2, -1)\n",
        "        x = self.activation(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.downsample(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    \n",
        "    \n",
        "class UpConv(nn.Module):\n",
        "\n",
        "    def __init__(self, scale, **args):\n",
        "        super(UpConv, self).__init__()\n",
        "        self.conv_block = Conv(**args)\n",
        "        self.upsample = nn.Upsample(scale_factor=scale, mode='linear', align_corners=False)\n",
        "\n",
        "            \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv_block(x)\n",
        "        x = self.upsample(x)\n",
        "        return x    \n",
        "    \n",
        "\n",
        "class EDModel_Skip(nn.Module):\n",
        "\n",
        "    def __init__(self, n_electrodes=30, n_freqs = 16, n_channels_out=21,  channels = [8, 16, 32, 32],  \n",
        "                 kernel_sizes=[3, 3, 3], strides=[4, 4, 4], dilation=[1, 1, 1] ):\n",
        "        \n",
        "        super(EDModel_Skip, self).__init__()\n",
        "        self.n_electrodes = n_electrodes\n",
        "        self.n_freqs = n_freqs\n",
        "        self.in_features = n_freqs * n_electrodes\n",
        "        self.n_channels_out = n_channels_out\n",
        "        self.depth = len(channels)-1\n",
        "        self.spatial_reduce = Conv(self.in_features, channels[0], kernel_size=3) \n",
        "        \n",
        "\n",
        "        self.downsample_blocks = nn.ModuleList([Conv(channels[i], channels[i+1], kernel_sizes[i],stride=strides[i],\n",
        "                                                     dilation=dilation[i]) for i in range(self.depth)])\n",
        "        channels = [ch for ch in channels[:-1]] + channels[-1:] # rearranges the channels to get ready for outpout\n",
        "        self.upsample_blocks = nn.ModuleList([UpConv(scale=strides[i], in_channels=channels[i+1] if i == self.depth-1 else channels[i+1]*2 ,\n",
        "                                                     out_channels=channels[i], kernel_size=kernel_sizes[i]) for i in range(self.depth-1, -1, -1)])\n",
        "        self.conv1x1_one = nn.Conv1d(channels[0]*2, self.n_channels_out, kernel_size=1, padding='same') \n",
        "      \n",
        "    def forward(self, x):\n",
        "\n",
        "        batch, elec, n_freq, time = x.shape\n",
        "        x = x.reshape(batch, -1, time)  \n",
        "        x = self.spatial_reduce(x)\n",
        "        skip_connection = []\n",
        "        \n",
        "        for i in range(self.depth):\n",
        "            skip_connection.append(x)\n",
        "            x = self.downsample_blocks[i](x)\n",
        "\n",
        "        for i in range(self.depth):\n",
        "            x = self.upsample_blocks[i](x)\n",
        "            x = torch.cat((x, skip_connection[-1 - i]), dim=1)\n",
        "        \n",
        "        x = self.conv1x1_one(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqpZYMLrhik0"
      },
      "outputs": [],
      "source": [
        "class TestCallback:\n",
        "    def __init__(self, test_x, subject_num, fg_num):\n",
        "        super().__init__()\n",
        "        self.test_x = test_x.T\n",
        "        self.fg_num = fg_num\n",
        "        self.subject = subject_num\n",
        "\n",
        "    def test(self, pl_module):\n",
        "        with torch.no_grad():\n",
        "            size = 64\n",
        "            bound = self.test_x.shape[0]//size * size\n",
        "            X_test = self.test_x[:bound]\n",
        "            x_batch = torch.from_numpy(X_test).float().to(\"cuda:0\")\n",
        "            x_batch = x_batch.T\n",
        "            x_batch = torch.unsqueeze(x_batch, 0)\n",
        "            y_hat = pl_module.model(x_batch)[0]\n",
        "            y_hat = y_hat.cpu().detach().numpy()\n",
        "            stride = 1\n",
        "            y_prediction = y_hat.T[::int(stride*(downsampling_f_s/100)), :]\n",
        "            y_prediction = np.pad(y_prediction, ((15, 15), (0, 0)), mode='edge')\n",
        "            y_prediction_tensor = torch.tensor(y_prediction).float()\n",
        "            y_prediction_upsampled = F.interpolate(y_prediction_tensor.unsqueeze(0).unsqueeze(0), scale_factor=(10, 1), mode=\"nearest\")\n",
        "            y_prediction_upsampled = y_prediction_upsampled.squeeze(0).squeeze(0).numpy()\n",
        "            y_prediction_upsampled = ndimage.gaussian_filter1d(y_prediction_upsampled.T, sigma=1).T\n",
        "\n",
        "            np.save(f\"{Path().resolve()}/submit/prediction{self.subject}.npy\", y_prediction_upsampled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0sH55qbhik0"
      },
      "source": [
        "# Train/Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HamL4ALhik0"
      },
      "outputs": [],
      "source": [
        "window = 256 \n",
        "learn_r = 8.42e-5 # learning rate\n",
        "decay_r = 1e-6 # Decay rate\n",
        "batchsize = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(3):\n",
        "    subject = i + 1\n",
        "    \n",
        "    encoder_args = dict(channels = [32, 32, 64, 64, 128, 128, 256], \n",
        "                        kernel_sizes=[ 9, 7, 7, 5, 5, 5],\n",
        "                        strides=[2, 2, 2, 2, 2, 2],\n",
        "                        dilation=[1,  1, 1, 1, 1,  1],\n",
        "                        n_electrodes = num_channels,\n",
        "                        n_freqs = num_wavelets,\n",
        "                        n_channels_out = num_fingers) # A set of features for the model\n",
        "\n",
        "    model = EDModel_Skip(**encoder_args).to(\"cuda:0\")\n",
        "    lighning_wrapper = Runner(model) # Wrapping in pytorch-lightning class\n",
        "\n",
        "\n",
        "\n",
        "    dm = DataModule(subject, batchsize, window, PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuwTdOcohik0"
      },
      "outputs": [],
      "source": [
        "Path(f\"{Path().resolve()}/submit\").mkdir(parents=True, exist_ok=True)\n",
        "for i in range(3):\n",
        "    subject = i + 1\n",
        "    #ecog_test = testpreprocess(ecog_data['leaderboard_ecog'][i][0])\n",
        "    #print(ecog_test.shape[0])\n",
        "    ecog_test = testpreprocess(ecog_data['truetest_data'][i][0])\n",
        "    num_channels = ecog_test.shape[0]\n",
        "    num_wavelets = ecog_test.shape[1]\n",
        "    num_fingers = 5\n",
        "    encoder_args = dict(channels = [32, 32, 64, 64, 128, 128, 256], \n",
        "                        kernel_sizes=[9, 7, 7, 5, 5, 5],\n",
        "                        strides=[2, 2, 2, 2, 2, 2],\n",
        "                        dilation=[1, 1, 1, 1, 1, 1],\n",
        "                        n_electrodes = num_channels,\n",
        "                        n_freqs = num_wavelets,\n",
        "                        n_channels_out = num_fingers) \n",
        "    trained_model = Runner.load_from_checkpoint(checkpoint_path = f\"{Path().resolve()}/checkpoints/model{subject}.ckpt\", model = EDModel_Skip(**encoder_args))\n",
        "    test_callback = TestCallback(ecog_test, subject, num_fingers)\n",
        "    trained_model = trained_model.to(\"cuda:0\")\n",
        "    test_callback.test(trained_model) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "QnOc89TChik0"
      },
      "outputs": [],
      "source": [
        "predictions = np.zeros((3,1), dtype=object)\n",
        "predictions[0,0] = np.load(f\"{Path().resolve()}/submit/prediction1.npy\")\n",
        "predictions[1,0] = np.load(f\"{Path().resolve()}/submit/prediction2.npy\")\n",
        "predictions[2,0] = np.load(f\"{Path().resolve()}/submit/prediction3.npy\")\n",
        "#save the array using the right format\n",
        "io.savemat('predictions.mat', {'predicted_dg':predictions})\n",
        "     "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "be521",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
